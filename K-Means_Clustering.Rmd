---
title: 'Final Project: K-Means Clustering'
output: html_document
---
## K-Means Clustering
### Zander Galluppi

```{r setup, echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
# Installing relevant packages / loading data
install.packages('rattle.data', repos='https://cran.r-project.org')
data(wine, package="rattle.data")

install.packages('fpc', repos='https://cran.r-project.org')
library('fpc')

data("iris")
```


#### K-means functions

```{r}
# K-means function that puts each entry of the input data into one of three bins based on Euclidean distance
# This is called in the kmeans_clustering() function whenever k-means clusters need to be calculated
# Parameter "cols" defines which columns of the original data frame to use in the algorithm
run_kmeans <- function(data,cols) {
  for (i in 1:nrow(data)) {
    # Calculates the distance from points k1, k2, and k3 for each entry in the data set
    k1_dist <- dist(rbind(k1, data[i,cols]))
    k2_dist <- dist(rbind(k2, data[i,cols]))
    k3_dist <- dist(rbind(k3, data[i,cols]))
    # Of those three distances, assign whichever is smallest to a cluster column in the generated k-means data frame
    if (min(k1_dist, k2_dist, k3_dist) == k1_dist) {
      kmeans_data$kmeans_clusters[i] = 1
    }
    if (min(k1_dist, k2_dist, k3_dist) == k2_dist) {
      kmeans_data$kmeans_clusters[i] = 2
    }
    if (min(k1_dist, k2_dist, k3_dist) == k3_dist) {
      kmeans_data$kmeans_clusters[i] = 3
    }
  }
  kmeans_data <<- kmeans_data
}

# A function that takes a data frame and relevant columns as arguments and performs three-point k-means clustering
kmeans_clustering <- function(data, cols) {
  # Generates a new vector for the k-means clusters and appends it to a calculated version of the data frame
  kmeans_clusters = vector(mode="numeric", length = nrow(data))
  kmeans_data <<- cbind(data, kmeans_clusters)
  # Selects three random entries in the data to serve as starting cluster points
  k1 <<- data[runif(1, 1, nrow(data)), cols]
  k2 <<- data[runif(1, 1, nrow(data)), cols]
  k3 <<- data[runif(1, 1, nrow(data)), cols]
  # Runs the k-means function above to generate a first set of clusters
  run_kmeans(data,cols)
  # While the last run of k-means clustering and the current run give different results (i.e. if there was reassignment of the cluster values), average the clustered points to form a new k1, k2, and k3, then perform the k-means clustering again
  while (identical(kmeans_clusters, kmeans_data$kmeans_clusters) == FALSE) {
     kmeans_clusters <- kmeans_data$kmeans_clusters
     k1 <<- lapply(kmeans_data[kmeans_data$kmeans_clusters == 1,][cols], mean)
     k2 <<- lapply(kmeans_data[kmeans_data$kmeans_clusters == 2,][cols], mean)
     k3 <<- lapply(kmeans_data[kmeans_data$kmeans_clusters == 3,][cols], mean)
     run_kmeans(data, cols)
   }
   return(plotcluster(kmeans_data[cols], kmeans_data$kmeans_clusters))
}

# A function for finding the mode of a data set with three possible outputs (for use in evaluating the k-means algorithm)
find_mode <- function(data) {
  counts <- vector(mode = "numeric", length = 3)
  counts[1] <- sum(data == 1)
  counts[2] <- sum(data == 2)
  counts[3] <- sum(data == 3)
  return(which(counts == max(counts)))
}

```

#### Wine data

```{r}
kmeans_clustering(wine, 2:14)
```

#### Method for Error of Clustering
```{r}
# Sort out the wine data by types
Type1wines <- kmeans_data[kmeans_data$Type == 1,]
Type2wines <- kmeans_data[kmeans_data$Type == 2,]
Type3wines <- kmeans_data[kmeans_data$Type == 3,]

# Find the mode of the k-means clusters for type 1 wines
Type1mode <- find_mode(Type1wines$kmeans_clusters)
# Then find the proportion of k-means assignments that are not the same as the mode (this percentage is a relative measure of the variability in cluster assignment vs. true wine type)
Type1ClusterError <<- sum(Type1wines$kmeans_clusters != Type1mode)/length(Type1wines$kmeans_clusters)

Type2mode <- find_mode(Type2wines$kmeans_clusters)
Type2ClusterError <<- sum(Type2wines$kmeans_clusters != Type2mode)/length(Type2wines$kmeans_clusters)

Type3mode <- find_mode(Type3wines$kmeans_clusters)
Type3ClusterError <<- sum(Type3wines$kmeans_clusters != Type3mode)/length(Type3wines$kmeans_clusters)

```


```{r, echo=FALSE}
paste("Type 1 wines have", round(Type1ClusterError*100,2),"% different cluster values")
paste("Type 2 wines have", round(Type2ClusterError*100,2),"% different cluster values")
paste("Type 3 wines have", round(Type3ClusterError*100,2),"% different cluster values")

```

The clusters are reasonably well-defined and delineated; however, there is a significant deviation from the wine type classification.


#### Scaled Wine Data

```{r}
kmeans_clustering(as.data.frame(scale(wine[2:14])), 1:13)
```

The scale function, for all the values in each column, subtracts the mean of the column entries, and then divides by the standard deviation of the column entries.  This centers the data around 0 with a st dev of 1.

```{r, echo=FALSE}
kmeans_data <- cbind(kmeans_data, wine$Type)

Type1wines <- kmeans_data[kmeans_data$'wine$Type' == 1,]
Type2wines <- kmeans_data[kmeans_data$'wine$Type' == 2,]
Type3wines <- kmeans_data[kmeans_data$'wine$Type' == 3,]

Type1mode <- find_mode(Type1wines$kmeans_clusters)
Type1ClusterError <<- sum(Type1wines$kmeans_clusters != Type1mode)/length(Type1wines$kmeans_clusters)

Type2mode <- find_mode(Type2wines$kmeans_clusters)
Type2ClusterError <<- sum(Type2wines$kmeans_clusters != Type2mode)/length(Type2wines$kmeans_clusters)

Type3mode <- find_mode(Type3wines$kmeans_clusters)
Type3ClusterError <<- sum(Type3wines$kmeans_clusters != Type3mode)/length(Type3wines$kmeans_clusters)

```

```{r, echo=FALSE}
paste("Scaled type 1 wines have", round(Type1ClusterError*100,2),"% different cluster values")
paste("Scaled type 2 wines have", round(Type2ClusterError*100,2),"% different cluster values")
paste("Scaled type 3 wines have", round(Type3ClusterError*100,2),"% different cluster values")

```

The scaling seems to greatly improve the delineation of the clusters and better correlates the data to the wine types.


#### Iris Data

```{r}
kmeans_clustering(iris, 1:4)
```


```{r, echo = FALSE}
# Sort out the iris data by types
SetosaIris <- kmeans_data[kmeans_data$Species == "setosa",]
VersicolorIris <- kmeans_data[kmeans_data$Species == "versicolor",]
VirginicaIris <- kmeans_data[kmeans_data$Species == "virginica",]

# Find the mode of the k-means clusters for setosa irises
SetosaIrisMode <- find_mode(SetosaIris$kmeans_clusters)
# Then find the proportion of k-means assignments that are not the same as the mode (this percentage is a relative measure of the variability in cluster assignment vs. true species)
SetosaClusterError <<- sum(SetosaIris$kmeans_clusters != SetosaIrisMode)/length(SetosaIris$kmeans_clusters)

VersicolorIrisMode <- find_mode(VersicolorIris$kmeans_clusters)
VersicolorClusterError <<- sum(VersicolorIris$kmeans_clusters != VersicolorIrisMode)/length(VersicolorIris$kmeans_clusters)

VirginicaMode <- find_mode(VirginicaIris$kmeans_clusters)
VirginicaClusterError <<- sum(VirginicaIris$kmeans_clusters != VirginicaMode)/length(VirginicaIris$kmeans_clusters)

```


```{r, echo=FALSE}
paste("Setosa irises have", round(SetosaClusterError*100,2),"% different cluster values")
paste("Versicolor irises have", round(VersicolorClusterError*100,2),"% different cluster values")
paste("Virginica irises have", round(VirginicaClusterError*100,2),"% different cluster values")

```

The clusters are much better defined before scaling than the wine data were.

#### Scaled Iris Data

```{r}
kmeans_clustering(as.data.frame(scale(iris[1:4])), 1:4)
```


```{r, echo=FALSE}
kmeans_data <- cbind(kmeans_data, iris$Species)

SetosaIris <- kmeans_data[kmeans_data$'iris$Species' == "setosa",]
VersicolorIris <- kmeans_data[kmeans_data$'iris$Species' == "versicolor",]
VirginicaIris <- kmeans_data[kmeans_data$'iris$Species' == "virginica",]

SetosaIrisMode <- find_mode(SetosaIris$kmeans_clusters)
SetosaClusterError <<- sum(SetosaIris$kmeans_clusters != SetosaIrisMode)/length(SetosaIris$kmeans_clusters)

VersicolorIrisMode <- find_mode(VersicolorIris$kmeans_clusters)
VersicolorClusterError <<- sum(VersicolorIris$kmeans_clusters != VersicolorIrisMode)/length(VersicolorIris$kmeans_clusters)

VirginicaMode <- find_mode(VirginicaIris$kmeans_clusters)
VirginicaClusterError <<- sum(VirginicaIris$kmeans_clusters != VirginicaMode)/length(VirginicaIris$kmeans_clusters)
```

```{r, echo=FALSE}
paste("Scaled setosa irises have", round(Type1ClusterError*100,2),"% different cluster values")
paste("Scaled versicolor irises have", round(Type2ClusterError*100,2),"% different cluster values")
paste("Scaled virginica irises have", round(Type3ClusterError*100,2),"% different cluster values")

```

The scale function again appears to generally improve upon the results as cluster 3 becomes much better defined; however, cluster 2 suffers a bit as a result.
